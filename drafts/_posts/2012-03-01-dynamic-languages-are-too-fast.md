---
layout: post
title:  Dynamic Languages Are Too Fast
authors:
    - <a href="http://github.com/JeffBezanson/">Jeff Bezanson</a>
    - <a href="http://karpinski.org/">Stefan Karpinski</a>
---

We're going to make a seemingly paradoxical claim:
*in order to be much faster, dynamic languages ought to be much slower.*
This strange assertion seems more like a koan than a legitimate idea about how to design dynamic programming languages.
However, it's a serious proposition, and it's central to the design of the Julia language.

Like many koans (and jokes), the key to enlightenment is changing frames of reference — and understanding which reference frame applies to which part of the koan.
In this case, the two distinct meanings of "speed" in this koan are:

1. Dynamic language speed when interpreted naïvely
2. Dynamic language speed when executed by a clever, type-inferencing JIT.

Decoded into these reference frames, our claim becomes:
in order to be much faster when executed by a clever, type-inferencing JIT, dynamic languages ought to be much slower when interpreted naïvely.
While this version of the claim is far less mysterious, it is still a rather non-obvious proposition that we have to provide an argument and some evidence for.

Pick any mainstream dynamic language out there today: Lisp, Perl, Python, Ruby, JavaScript, Matlab, Lua.
When every single one of these languages was first implemented, that implementation used a relatively naïve interpreter to execute programs.
Compiling source to bytecode and then interpreting bytecode eventually became standard since it avoids re-parsing the source every time it executes, but even that was not something most early implementations did.
Interpretation introduces a fair amount of overhead:
a really good interpreter can execute code 10-50 times slower than native code with comparable functionality generated by a compiler.
Less fast interpreters often run thousands of times slower than native code with comparable functionality.
For many purposes, that's fast enough, and the tradeoff of speed for ease-of-use provided by dynamic languages is worth it.
So the popularity of dynamic languages grew.

As the popularity of dynamic languages has grown, various approaches have been used to speed up their execution.
These days, there are a number of very impressive projects that have managed to achieve vast speedups in the execution of various dynamic languages:

- JavaScript:   [V8](http://code.google.com/p/v8/)
- Lua:          [LuaJIT](http://luajit.org/luajit.html)
- Python:       [PyPy](http://pypy.org/)
- Ruby:         [Mirah](http://www.mirah.org/), [DRuby](http://www.cs.umd.edu/projects/PL/druby/) (neither is quite Ruby, but they're close)
- Matlab:       [Matlab JIT](http://www.mathworks.com/products/matlab/description2.html)
- Lisp:         too many to list

These projects achieve better than naïve interpretation speed through a variety of techniques, including just-in-time (JIT) compilation and type tracing.
JIT compilation generates native machine code at run-time, just before execution, avoiding the overhead of interpretation when the code executes.
Type tracing entails running a generic, instrumented version of code for some number of iterations, keeping track of what types of values are actually bound to variables, and then JIT compiling fast, specialized versions of the code assuming those types and only falling back on the generic version if some values encountered fail to match the assumed types.

With these techniques, dynamic languages can be made much, much faster.
For certain kinds of code, they can even match or beat the performance of a language like C.
Consider these benchmark results (a snapshot of <a href="/#High-Performance+JIT+Compiler" target="_blank">the ones on our main page</a>):

<div class="figure">
<table class="benchmarks">
<colgroup>
<col class="name"></col>
<col class="relative" span="6"></col>
</colgroup>
<thead>
<tr><td></td><th class="system">Julia</th><th class="system">NumPy</th><th class="system">Matlab</th><th class="system">Octave</th><th class="system">R</th><th class="system">JavaScript</th></tr>
<tr><td></td><td class="version">2c3c67cd</td><td class="version">1.5.1</td><td class="version">R2011a</td><td class="version">3.4</td><td class="version">2.9.0</td><td class="version">V8 3.6.6.11</td></tr>
</thead>
<tbody>
<tr><th>fib</th><td class="data">1.97</td><td class="data">30.74</td><td class="data">1360.47</td><td class="data">2463.97</td><td class="data">334.94</td><td class="data">1.48</td></tr>
<tr><th>parse_int</th><td class="data">1.27</td><td class="data">16.49</td><td class="data">827.13</td><td class="data">6871.04</td><td class="data">1082.67</td><td class="data">2.12</td></tr>
<tr><th>quicksort</th><td class="data">1.31</td><td class="data">61.73</td><td class="data">135.51</td><td class="data">3357.78</td><td class="data">971.06</td><td class="data">6.61</td></tr>
<tr><th>mandel</th><td class="data">6.88</td><td class="data">31.98</td><td class="data">66.27</td><td class="data">870.55</td><td class="data">253.10</td><td class="data">5.73</td></tr>
<tr><th>pi_sum</th><td class="data">0.74</td><td class="data">18.77</td><td class="data">1.09</td><td class="data">356.08</td><td class="data">269.19</td><td class="data">0.75</td></tr>
<tr><th>rand_mat_stat</th><td class="data">4.12</td><td class="data">40.98</td><td class="data">12.20</td><td class="data">57.39</td><td class="data">32.39</td><td class="data">8.32</td></tr>
</tbody>
</table>
<p class="caption"><b>Figure:</b>
benchmark times relative to C++ (smaller is better).
</p>
</div>

**Note:** We've omitted the matrix multiplication benchmark since it doesn't measure dynamic language speed;
rather, it measures how fast each language can get out of the way and call a faster language like Fortran or C.
Moreover, it's unfair to JavaScript, which can't call a BLAS and is forced to use a very naïve matrix multiply, which just muddles the discussion.

The V8 engine always manages to be better than 10x slower than C++.
In two cases it's around 2x slower than C++, and in once case, it's actually 25% faster.
Matlab's JIT also manages to generate code that's about as fast as C for the pi summation benchmark, which is a tight scalar loop of computations with 64-bit floats.
By JITing good native code and using clever tricks like type tracing (which V8 heavily relies on), it is possible to get pretty good performance most of the time and very good performance some of the time.
However, there remain situations where even these clever implementations still only get down to 6-8x slower than C++.
This raises the question of how to close the rest of this performance gap between static and dynamic languages — and more to the point, whether it is even possible to do so.
Will a patchwork of new clever tricks get us the rest of the way?
Or is there a more consistent approach that can close the gap across the board?

Fast implementations of traditional dynamic languages will continue to improve.
However, we suspect that a lot of the low hanging fruit has already been picked.
Various slow cases may be sped up by new techniques, but as more techniques are added, implementation complexity inevitably grows — and interactions between features in language implementations tend to be tightly coupled, causing a combinatorial explosion in code complexity as more features are added.
This leads us to look for a new approach:
a more consistent, simpler way to make dynamic languages faster.

We have found what we believe to be a promising approach to closing the performance gap between dynamic and static languages.
However, it requires going back to the drawing board and designing a dynamic language from scratch to take maximum advantage of JIT technology.
To some extent, this entails doing without some of the more extreme dynamism of languages like Ruby — for example, not allowing adding fields to composite types after they've been created.
Another aspect, however, is adding a sophisticated type system and multiple dispatch as central features of the language.
While a few dynamic languages such as Common Lisp and Clojure support type declarations and multiple dispatch as add-on, optional features, having these as core language features, used everywhere has previously been the domain of statically compiled languages.
Our experiment then, is to take these traditionally static features and make them central to a dynamic language.

Julia is our implementation of this new approach to dynamic language design.
In the absence of any optimizations, the relative complexity of Julia's type and dispatch systems compared to other dynamic languages makes it much, much slower.
However, these features also allow certain optimizations, in the presence of which the language suddenly becomes fast:
more often than not, Julia is within 2x of C.
With further work, we believe we can close that gap all the way by adding a few more high-level optimizations and smoothing away the rougher edges of our implementation.
